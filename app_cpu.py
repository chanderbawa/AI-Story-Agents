#!/usr/bin/env python3
"""
CPU-Optimized launcher for AI Story Agents Web Interface
Use this for running on machines without GPU
"""

from web_interface import StoryWebInterface
import warnings

# Suppress warnings for cleaner output
warnings.filterwarnings('ignore')

if __name__ == '__main__':
    print("=" * 70)
    print("üñ•Ô∏è  AI STORY AGENTS - CPU MODE")
    print("=" * 70)
    print()
    print("‚öôÔ∏è  Configuration:")
    print("   ‚Ä¢ Using CPU-optimized models")
    print("   ‚Ä¢ TinyLlama for text generation (faster)")
    print("   ‚Ä¢ Stable Diffusion 1.5 with reduced steps")
    print("   ‚Ä¢ Smaller image dimensions (512x512)")
    print()
    print("‚è±Ô∏è  Expected Generation Time:")
    print("   ‚Ä¢ Short story: 30-45 minutes")
    print("   ‚Ä¢ Medium story: 45-60 minutes")
    print("   ‚Ä¢ Long story: 60-90 minutes")
    print()
    print("üí° Tips:")
    print("   ‚Ä¢ Start with SHORT stories to test")
    print("   ‚Ä¢ Close other applications to free up RAM")
    print("   ‚Ä¢ Be patient - CPU generation is slower but works!")
    print()
    print("=" * 70)
    print()
    
    # Create and launch interface with CPU config
    web_interface = StoryWebInterface(config_path='config/agents_config_cpu.yaml')
    
    print("üöÄ Starting web interface on http://localhost:7860")
    print("   Press Ctrl+C to stop")
    print()
    
    # Launch without share link (local only)
    web_interface.launch(share=False, server_port=7860)
