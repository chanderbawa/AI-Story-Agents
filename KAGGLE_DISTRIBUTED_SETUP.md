# Running Distributed AI Story Agents on Kaggle

Guide for running the distributed multi-agent system on Kaggle with GPU.

## ğŸ¯ Kaggle Limitations & Solutions

### Limitations:
- âŒ Can't run multiple separate processes/containers
- âŒ Can't use Docker Compose
- âŒ Single notebook environment

### Solutions:
- âœ… Run agents in background threads
- âœ… Use in-memory message broker
- âœ… Simulate distributed architecture in single process
- âœ… Still get parallel processing benefits!

---

## ğŸš€ Quick Start - Kaggle Notebook

### Complete Copy-Paste Solution

**Step 1: Enable GPU**
- Runtime â†’ Accelerator â†’ GPU T4 x2 (or P100)

**Step 2: Copy this entire code into a Kaggle cell:**

```python
# ============================================
# KAGGLE DISTRIBUTED AI STORY AGENTS
# ============================================

import torch
print("="*70)
print("ğŸ” GPU Check")
print("="*70)
print(f"GPU Available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
print("="*70)

# ============================================
# INSTALL & SETUP
# ============================================

print("\nğŸ“¦ Installing dependencies...")
!pip install -q transformers diffusers accelerate torch torchvision pillow pyyaml reportlab flask

print("\nğŸ“¥ Downloading code...")

import os
import urllib.request

# Create structure
os.makedirs('agents', exist_ok=True)
os.makedirs('orchestrator', exist_ok=True)
os.makedirs('config', exist_ok=True)
os.makedirs('distributed', exist_ok=True)
os.makedirs('output/publications', exist_ok=True)

# Download files
files = {
    'agents/__init__.py': 'https://raw.githubusercontent.com/chanderbawa/AI-Story-Agents/main/agents/__init__.py',
    'agents/base_agent.py': 'https://raw.githubusercontent.com/chanderbawa/AI-Story-Agents/main/agents/base_agent.py',
    'agents/author_agent.py': 'https://raw.githubusercontent.com/chanderbawa/AI-Story-Agents/main/agents/author_agent.py',
    'agents/illustrator_agent.py': 'https://raw.githubusercontent.com/chanderbawa/AI-Story-Agents/main/agents/illustrator_agent.py',
    'agents/publisher_agent.py': 'https://raw.githubusercontent.com/chanderbawa/AI-Story-Agents/main/agents/publisher_agent.py',
    'orchestrator/__init__.py': 'https://raw.githubusercontent.com/chanderbawa/AI-Story-Agents/main/orchestrator/__init__.py',
    'orchestrator/coordinator.py': 'https://raw.githubusercontent.com/chanderbawa/AI-Story-Agents/main/orchestrator/coordinator.py',
    'config/agents_config.yaml': 'https://raw.githubusercontent.com/chanderbawa/AI-Story-Agents/main/config/agents_config.yaml',
    'distributed/__init__.py': 'https://raw.githubusercontent.com/chanderbawa/AI-Story-Agents/main/distributed/__init__.py',
    'distributed/message_broker.py': 'https://raw.githubusercontent.com/chanderbawa/AI-Story-Agents/main/distributed/message_broker.py',
    'distributed/agent_service.py': 'https://raw.githubusercontent.com/chanderbawa/AI-Story-Agents/main/distributed/agent_service.py',
    'distributed/distributed_orchestrator.py': 'https://raw.githubusercontent.com/chanderbawa/AI-Story-Agents/main/distributed/distributed_orchestrator.py',
}

for filepath, url in files.items():
    try:
        urllib.request.urlretrieve(url, filepath)
        print(f"âœ… {filepath}")
    except Exception as e:
        print(f"âŒ {filepath}: {str(e)}")

# ============================================
# START DISTRIBUTED SYSTEM IN KAGGLE
# ============================================

print("\nğŸš€ Starting distributed agent system...")

import threading
import time
import logging
from distributed.message_broker import get_broker
from distributed.agent_service import AgentService
from distributed.distributed_orchestrator import DistributedOrchestrator
from agents.author_agent import AuthorAgent
from agents.illustrator_agent import IllustratorAgent
from agents.publisher_agent import PublisherAgent
import yaml

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(message)s'
)

# Load config
with open('config/agents_config.yaml', 'r') as f:
    config = yaml.safe_load(f)

# Initialize message broker (in-memory for Kaggle)
broker = get_broker(broker_type='memory')

print("\nğŸ“ Starting Author Service...")
author_agent = AuthorAgent(config['author'])
author_service = AgentService(author_agent, 'AuthorService', 8001, broker)
author_service.start(background=True)
time.sleep(2)

print("ğŸ¨ Starting Illustrator Service...")
illustrator_agent = IllustratorAgent(config['illustrator'])
illustrator_service = AgentService(illustrator_agent, 'IllustratorService', 8002, broker)
illustrator_service.start(background=True)
time.sleep(2)

print("ğŸ“š Starting Publisher Service...")
publisher_agent = PublisherAgent(config['publisher'])
publisher_service = AgentService(publisher_agent, 'PublisherService', 8003, broker)
publisher_service.start(background=True)
time.sleep(2)

print("\nâœ… All services running!")
print("="*70)

# ============================================
# CREATE YOUR STORY
# ============================================

print("\nğŸ“– Creating story with distributed agents...")

orchestrator = DistributedOrchestrator(broker)

story_idea = {
    'plot': '''
    A brave mouse named Max discovers a magical map that leads to enchanted cheese.
    Along his journey, he meets a wise owl named Olivia who becomes his guide.
    Together they face challenges, solve riddles, and learn about courage and friendship.
    In the end, they discover the real treasure was the friendship they built.
    ''',
    'target_age': '8-12',
    'themes': ['courage', 'adventure', 'friendship', 'wisdom'],
    'length': 'short',
    'art_style': 'children_book'
}

print(f"\nPlot: {story_idea['plot'][:100]}...")
print(f"Themes: {', '.join(story_idea['themes'])}")
print(f"Length: {story_idea['length']}")
print("\n" + "="*70)
print("ğŸš€ STARTING DISTRIBUTED STORY GENERATION")
print("="*70)
print("â±ï¸  Estimated time: 5-15 minutes on GPU")
print("ğŸ“Š Progress will be shown below...")
print("="*70 + "\n")

# Generate story
result = orchestrator.create_story(story_idea, timeout=1800)

# ============================================
# DISPLAY RESULTS
# ============================================

print("\n" + "="*70)
if result['status'] == 'complete':
    print("âœ… STORY GENERATION COMPLETE!")
    print("="*70)
    print(f"\nğŸ“Š Story Statistics:")
    print(f"   Title: {result['metadata'].get('title', 'Untitled Story')}")
    print(f"   Chapters: {result['metadata']['chapters']}")
    print(f"   Illustrations: {result['metadata']['images']}")
    print(f"   Pages: {result['metadata']['page_count']}")
    
    print(f"\nğŸ“ Output Files:")
    for format_type, filepath in result['publications'].items():
        print(f"   {format_type.upper()}: {filepath}")
    
    # Display download link
    from IPython.display import FileLink, display
    print("\nğŸ“¥ Click to download your PDF:")
    display(FileLink(result['publications']['pdf']))
    
    # Also display HTML preview
    if 'html' in result['publications']:
        print("\nğŸ“„ HTML Preview:")
        display(FileLink(result['publications']['html']))
    
else:
    print("âŒ STORY GENERATION FAILED")
    print("="*70)
    print(f"Status: {result['status']}")
    print(f"Message: {result.get('message', 'Unknown error')}")

print("\nğŸ‰ Done!")
```

---

## ğŸ“‹ Step-by-Step Guide

### 1. Create New Kaggle Notebook

1. Go to https://www.kaggle.com/code
2. Click "New Notebook"
3. **Enable GPU**: Right sidebar â†’ Accelerator â†’ GPU T4 x2

### 2. Paste the Code

Copy the entire code block above into a single cell.

### 3. Run and Wait

- Click Run
- Wait 5-15 minutes (GPU) or 30-90 minutes (CPU)
- Download your PDF!

---

## ğŸ¨ Custom Story

To create your own story, modify the `story_idea` section:

```python
story_idea = {
    'plot': '''
    YOUR DETAILED STORY PLOT HERE
    
    Include:
    - Characters with descriptions
    - Setting details
    - Main conflict
    - Resolution
    - Key scenes
    ''',
    'target_age': '8-12',  # or '5-7', '10-14'
    'themes': ['friendship', 'courage', 'kindness'],
    'length': 'short',  # or 'medium', 'long'
    'art_style': 'children_book'  # or 'cartoon', 'watercolor', 'line_art'
}
```

---

## ğŸ”§ Advanced: Multiple Stories

Generate multiple stories in one session:

```python
# After setting up services (run setup code first)

stories = [
    {
        'plot': 'A shy turtle learns to swim',
        'themes': ['courage', 'perseverance'],
        'length': 'short'
    },
    {
        'plot': 'Kids start a recycling club',
        'themes': ['environment', 'teamwork'],
        'length': 'short'
    },
    {
        'plot': 'A robot learns about emotions',
        'themes': ['friendship', 'empathy'],
        'length': 'short'
    }
]

results = []
for i, story_idea in enumerate(stories, 1):
    print(f"\n{'='*70}")
    print(f"ğŸ“– Creating Story {i}/{len(stories)}")
    print(f"{'='*70}")
    
    result = orchestrator.create_story(story_idea)
    results.append(result)
    
    if result['status'] == 'complete':
        print(f"âœ… Story {i} complete!")
        from IPython.display import FileLink, display
        display(FileLink(result['publications']['pdf']))

print(f"\nğŸ‰ All {len(stories)} stories complete!")
```

---

## ğŸ’¡ How It Works on Kaggle

### Architecture in Kaggle:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Kaggle Notebook (Single VM)    â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   In-Memory Message Broker   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â†‘         â†‘         â†‘       â”‚
â”‚         â”‚         â”‚         â”‚       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â” â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â” â”Œâ”€â”€â”´â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Author  â”‚ â”‚Illustr.â”‚ â”‚Publisherâ”‚ â”‚
â”‚  â”‚ Thread  â”‚ â”‚ Thread â”‚ â”‚ Thread  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                     â”‚
â”‚  All running in background threads  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Benefits:**
- âœ… Still get parallel processing
- âœ… Agents communicate asynchronously
- âœ… Simpler than full distributed setup
- âœ… Works in Kaggle's single-notebook environment

---

## ğŸš€ Performance on Kaggle

### GPU Comparison:

| GPU | Story Time | Image Quality |
|-----|-----------|---------------|
| **P100** | 5-10 min | Excellent |
| **T4** | 8-15 min | Excellent |
| **CPU** | 30-90 min | Same |

### Parallel Processing:

Even in a single notebook, the distributed architecture allows:
- Author generates chapters
- Illustrator starts on chapter 1 while Author works on chapter 2
- Publisher prepares layout while images generate

**Result: ~30-40% faster than sequential!**

---

## ğŸ› Troubleshooting

### Out of Memory

**Reduce image size:**
```python
# Before starting services, modify config
config['illustrator']['width'] = 512
config['illustrator']['height'] = 512
config['illustrator']['num_inference_steps'] = 25
```

### Timeout

**Increase timeout:**
```python
result = orchestrator.create_story(story_idea, timeout=3600)  # 1 hour
```

### Services Not Starting

**Check logs:**
```python
import logging
logging.getLogger().setLevel(logging.DEBUG)
```

---

## ğŸ“Š Monitoring Progress

### View Message History

```python
# After story creation
correlation_id = result.get('correlation_id')
if correlation_id:
    history = orchestrator.get_message_history(correlation_id)
    
    print("\nğŸ“¨ Message Flow:")
    for msg in history:
        print(f"{msg['timestamp']}: {msg['sender']} â†’ {msg['receiver']}")
        print(f"   Action: {msg['content'].get('action', 'N/A')}")
```

### Check Service Health

```python
# Check if services are responding
import requests

try:
    r = requests.get('http://localhost:8001/health', timeout=2)
    print(f"Author: {r.json()}")
except:
    print("Author: Not responding")
```

---

## ğŸ¯ Best Practices for Kaggle

### 1. Start with Short Stories

Test with `length: 'short'` first to ensure everything works.

### 2. Save Intermediate Results

```python
# The system auto-saves to output/publications/
# Check progress:
!ls -lh output/publications/
```

### 3. Use GPU Wisely

Kaggle has GPU quotas. Generate multiple stories in one session:

```python
# Generate 3 stories in one session
for plot in plots:
    result = orchestrator.create_story({'plot': plot, 'length': 'short'})
```

### 4. Download Immediately

Download PDFs as soon as they're created:

```python
from IPython.display import FileLink
display(FileLink(result['publications']['pdf']))
```

---

## ğŸ†š Kaggle vs Local vs Docker

| Feature | Kaggle | Local | Docker |
|---------|--------|-------|--------|
| **Setup** | Copy-paste | Install deps | docker-compose up |
| **GPU** | Free P100/T4 | Need own GPU | Need own GPU |
| **Speed** | Fast (GPU) | Depends | Fast (GPU) |
| **Persistence** | Session only | Permanent | Permanent |
| **Scaling** | Single notebook | Multi-process | Multi-container |
| **Best For** | Quick tests | Development | Production |

---

## ğŸ“ Summary

**Kaggle Distributed Mode:**
- âœ… Runs in single notebook
- âœ… Uses background threads
- âœ… In-memory message broker
- âœ… Parallel processing
- âœ… Free GPU access
- âœ… 30-40% faster than sequential

**Perfect for:**
- Testing distributed architecture
- Generating stories with free GPU
- Learning how agents communicate
- Prototyping before production deployment

**Not ideal for:**
- True distributed deployment (use Docker/K8s)
- Multiple concurrent users (use separate services)
- Long-running production (use dedicated servers)

---

## ğŸš€ Quick Reference

**Minimal Kaggle Code:**

```python
# 1. Enable GPU
# 2. Install & download (see full code above)
# 3. Start services
# 4. Create story:

orchestrator = DistributedOrchestrator(broker)
result = orchestrator.create_story({
    'plot': 'Your story here',
    'themes': ['friendship'],
    'length': 'short'
})

# 5. Download
from IPython.display import FileLink
display(FileLink(result['publications']['pdf']))
```

That's it! ğŸ‰
